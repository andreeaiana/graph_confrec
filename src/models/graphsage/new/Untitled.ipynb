{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarities import Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\", \"..\", \"data\"))\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\", \"..\", \"utils\"))\n",
    "from DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get test data with abstracts and citations ready for evaluation\n",
    "d = DataLoader()\n",
    "d.validation_data_with_abstracts_citations()\n",
    "query_test = list(zip(list(d.data.chapter), list(d.data.chapter_title), \n",
    "                 list(d.data.chapter_abstract), list(d.data.chapter_citations)))\n",
    "\n",
    "conferences_truth = list()\n",
    "confidences_truth = list()\n",
    "\n",
    "for conferenceseries in list(d.data.conferenceseries):\n",
    "    conferences_truth.append([conferenceseries])\n",
    "    confidences_truth.append([1])\n",
    "\n",
    "truth = [conferences_truth, confidences_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = list(d.data.chapter)\n",
    "len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = DataLoader()\n",
    "d.training_data_with_abstracts_citations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = list(d.data[\"chapter\"])\n",
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_file = \"../../../data/processed/graphsage/AVG_2L/graphsage_mean_small_0.000010/embeddings.npy\"\n",
    "emb_ids_file = \"../../../data/processed/graphsage/AVG_2L/graphsage_mean_small_0.000010/embeddings_ids.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(emb_file)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map embeddings to node ids\n",
    "emb_ids = {}\n",
    "with open(emb_ids_file) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        emb_ids[line.strip()] = i\n",
    "emb = embeddings[[emb_ids[id] for id in train_ids]]\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ids = {}\n",
    "with open(emb_ids_file) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        emb_ids[line.strip()] = i\n",
    "val_emb = embeddings[[emb_ids[id] for id in val_ids]]\n",
    "len(val_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Similarities(emb, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "topn = len(val_emb)\n",
    "recs = 10\n",
    "similarities = []\n",
    "with tqdm(total=topn) as pbar:\n",
    "    for vector in val_emb:\n",
    "        similarities.append(sim.similar_by_vector(vector, topn=topn))\n",
    "        pbar.update(1)\n",
    "len(similarities)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = []\n",
    "confidences = []\n",
    "with tqdm(total=len(similarities)) as pbar:\n",
    "    for similarity in similarities:\n",
    "        confer = set()\n",
    "        confid = []\n",
    "        for i in range(len(similarity)):\n",
    "            l = len(confer)\n",
    "            if l<10:\n",
    "                confer.add(list(d.data[d.data.chapter==similarity[i][0]].conferenceseries)[0])\n",
    "                if len(confer) != l:\n",
    "                    confid.append(similarity[i][1])\n",
    "        conferences.append(list(confer))\n",
    "        confidences.append(confid)\n",
    "        pbar.update(1)\n",
    "results = [conferences, confidences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\", \"evaluations\"))\n",
    "from EvaluationContainer import EvaluationContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = EvaluationContainer()\n",
    "evaluation.evaluate(results,truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load training data from file\n",
    "# Step 2: Load test data from DataLoader\n",
    "d_test = DataLoader()\n",
    "df_test = d_test.test_data_with_abstracts_citations().data\n",
    "# Step 3: Pass df_test, G_train to preprocess_data.test()\n",
    "# Step 4: Retrieve new graph, id_map, features\n",
    "# Step 5: Get new embeddings\n",
    "# Step 6: Map test ids to embeddings\n",
    "# Step 7: Call classifier or similarities\n",
    "# Step 8: Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels (change for conferences)\n",
    "class_map = json.load(open(class_map_file))\n",
    "labels_train = [class_map[str(id)] for id in train_ids]\n",
    "len(labels_train)\n",
    "\n",
    "type(labels_train)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "labels = encoder.fit_transform(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\"python\", \"unsupervised_train.py\", \"--train_prefix\", \"example_data/toy-ppi\", \"--model\", \"graphsage_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "    # Poll process for new output until finished\n",
    "    while True:\n",
    "        nextline = process.stdout.readline()\n",
    "        if nextline == '' and process.poll() is not None:\n",
    "            break\n",
    "        sys.stdout.write(nextline)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    exitCode = process.returncode\n",
    "    if exitCode == 0:\n",
    "        print(\"Finished with exit code {}.\".format(str(exitCode)))\n",
    "    else:\n",
    "        raise ProcessException(command, exitCode, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=execute(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
